{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V6E1",
      "authorship_tag": "ABX9TyNR0kDWOfm4tfNHIEsyJZ4w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cartiktq/AcademicAnalytics/blob/main/KnowledgeGraphGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "S = \"\"\"from langgraph.graph import StateGraph, END\n",
        "from typing import TypedDict, List, Dict, Any\n",
        "from agents import (\n",
        "    generate_notes,             # Node 1\n",
        "    anonymize_notes,           # Node 2\n",
        "    evaluate_anonymization,    # Node 3\n",
        "    extract_entities,          # Node 4\n",
        "    map_to_umls_concepts,      # Node 5\n",
        "    map_to_local_aui,          # Node 6\n",
        "    build_patient_knowledge_graph,  # Node 7\n",
        "    visualize_knowledge_graph       # Node 8\n",
        ")\n",
        "\n",
        "class WorkflowState(TypedDict):\n",
        "    raw_notes_folder: str\n",
        "    anonymized_folder: str\n",
        "    comparison_metric: float\n",
        "    extracted_csv: str\n",
        "    umls_csv: str\n",
        "    aui_csv: str\n",
        "    graph_objects: List[Dict[str, Any]]\n",
        "    visualizations: List[Any]\n",
        "\n",
        "graph = StateGraph(WorkflowState)\n",
        "\n",
        "# Register nodes\n",
        "graph.add_node(\"generate_notes\", generate_notes)\n",
        "graph.add_node(\"anonymize_notes\", anonymize_notes)\n",
        "graph.add_node(\"evaluate_anonymization\", evaluate_anonymization)\n",
        "graph.add_node(\"extract_entities\", extract_entities)\n",
        "graph.add_node(\"map_to_umls_concepts\", map_to_umls_concepts)\n",
        "graph.add_node(\"map_to_local_aui\", map_to_local_aui)\n",
        "graph.add_node(\"build_knowledge_graph\", build_patient_knowledge_graph)\n",
        "graph.add_node(\"visualize_knowledge_graph\", visualize_knowledge_graph)\n",
        "\n",
        "# Edges (linear)\n",
        "graph.set_entry_point(\"generate_notes\")\n",
        "graph.add_edge(\"generate_notes\", \"anonymize_notes\")\n",
        "graph.add_edge(\"anonymize_notes\", \"evaluate_anonymization\")\n",
        "graph.add_edge(\"evaluate_anonymization\", \"extract_entities\")\n",
        "graph.add_edge(\"extract_entities\", \"map_to_umls_concepts\")\n",
        "graph.add_edge(\"map_to_umls_concepts\", \"map_to_local_aui\")\n",
        "graph.add_edge(\"map_to_local_aui\", \"build_knowledge_graph\")\n",
        "graph.add_edge(\"build_knowledge_graph\", \"visualize_knowledge_graph\")\n",
        "graph.add_edge(\"visualize_knowledge_graph\", END)\n",
        "\n",
        "app = graph.compile()\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "I0a_eLjm1iHx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install faker transformers torch sacremoses langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWHeDgCQ625k",
        "outputId": "0e2dbf71-a30b-4ab7-e01e-7c7a088d2399"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faker in /usr/local/lib/python3.11/dist-packages (37.4.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cpu)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.11/dist-packages (0.1.1)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.4.8)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sacremoses) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from sacremoses) (1.5.1)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.65)\n",
            "Requirement already satisfied: langgraph-checkpoint>=2.0.26 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.26)\n",
            "Requirement already satisfied: langgraph-prebuilt>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.2.2)\n",
            "Requirement already satisfied: langgraph-sdk>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.70)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.5)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (0.3.45)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint>=2.0.26->langgraph) (1.10.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#def generate_notes(state: WorkflowState) -> WorkflowState:\n",
        "def generate_notes():\n",
        "    from faker import Faker\n",
        "    import os\n",
        "    import random\n",
        "    from datetime import datetime, timedelta\n",
        "\n",
        "    fake = Faker()\n",
        "    output_dir = \"raw_clinical_notes\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    physical_symptoms = [\n",
        "    \"Developmental Delay\", \"Speech and Language Impairment\", \"Hypotonia\", \"Seizures\",\n",
        "    \"Gastrointestinal Issues\", \"Sleep Disturbances\", \"Dysmorphia\", \"Lymphedema\",\n",
        "    \"Renal Abnormalities\", \"Thermoregulation Issues\", \"Abnormalities of Nails\"\n",
        "]\n",
        "    behavioral_symptoms = [\n",
        "    \"Autism Spectrum Disorder (ASD) Features\", \"Intellectual Disability\", \"Anxiety\",\n",
        "    \"Aggression/Self-Injurious Behaviors\", \"Hyperactivity/Impulsivity\",\n",
        "    \"Sensory Processing Differences\", \"Compulsive Behaviors\", \"Mood Dysregulation\"\n",
        "]\n",
        "    prescriptions = [\n",
        "    \"Levetiracetam\", \"Valproic Acid\", \"Lamotrigine\", \"Fluoxetine\", \"Sertraline\",\n",
        "    \"Risperidone\", \"Aripiprazole\", \"Melatonin\", \"Polyethylene glycol\", \"Omeprazole\",\n",
        "    \"Ranitidine\", \"Methylphenidate\"\n",
        "]\n",
        "    lab_tests = [\n",
        "    \"Chromosomal Microarray Analysis (CMA)\", \"FISH\", \"Karyotype\", \"EEG\",\n",
        "    \"Metabolic Screens\", \"Renal Ultrasound\", \"GI Motility Studies\"\n",
        "]\n",
        "    therapies = [\n",
        "    \"Early Intervention Programs\", \"Speech and Language Therapy (SLT)\",\n",
        "    \"Occupational Therapy (OT)\", \"Physical Therapy (PT)\", \"Applied Behavior Analysis (ABA) Therapy\",\n",
        "    \"Feeding Therapy\", \"Behavioral Therapy/Parent Training\", \"Surgical Interventions\"\n",
        "]\n",
        "    comorbidities = [\n",
        "    \"Autism Spectrum Disorder (ASD)\", \"Epilepsy/Seizure Disorder\", \"Gastrointestinal Disorders\",\n",
        "    \"Sleep Disorders\", \"Anxiety Disorders\", \"ADHD\", \"Obesity\", \"Lymphedema\",\n",
        "    \"Renal Anomalies\", \"Immunodeficiency\"\n",
        "]\n",
        "\n",
        "    for patient_id in range(1, 101):\n",
        "        num_visits = random.randint(8, 10)\n",
        "        base_date = datetime.today()\n",
        "        for visit in range(num_visits):\n",
        "            visit_date = base_date - timedelta(days=random.randint(0, 365*2))\n",
        "            note = f\"\"\"\n",
        "            Patient: {fake.name()}\n",
        "            DOB: {fake.date_of_birth()}\n",
        "            Visit Date: {visit_date.strftime('%Y-%m-%d')}\n",
        "            Diagnoses: Phelan-McDermid Syndrome\n",
        "            Symptoms: {random.sample(physical_symptoms, 4)}\n",
        "            Behavioral Symptoms: {random.sample(behavioral_symptoms, 2)}\n",
        "            Labs: {random.sample(lab_tests, 2)}\n",
        "            Prescriptions: {random.sample(prescriptions, 2)}\n",
        "            Therapies: {random.sample(therapies, 2)}\n",
        "            Comorbidities: {random.sample(comorbidities, 2)}\n",
        "            \"\"\"\n",
        "            fname = f\"clinical_note_{visit}_for_patient_{patient_id}_{visit_date.strftime('%Y-%m-%d')}.txt\"\n",
        "            with open(os.path.join(output_dir, fname), \"w\") as f:\n",
        "                f.write(note)\n",
        "\n",
        "#    state[\"raw_notes_folder\"] = output_dir\n",
        "#    return state\n"
      ],
      "metadata": {
        "id": "7Oy0aVrd4tDc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_notes()"
      ],
      "metadata": {
        "id": "KrVScvMI6wFT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install presidio-analyzer presidio-anonymizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgXomUoU6zlh",
        "outputId": "5c7088ee-6f28-45fe-aa64-ab153fb58c10"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting presidio-analyzer\n",
            "  Downloading presidio_analyzer-2.2.358-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting presidio-anonymizer\n",
            "  Downloading presidio_anonymizer-2.2.358-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting phonenumbers<9.0.0,>=8.12 (from presidio-analyzer)\n",
            "  Downloading phonenumbers-8.13.55-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from presidio-analyzer) (6.0.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from presidio-analyzer) (2024.11.6)\n",
            "Requirement already satisfied: spacy!=3.7.0,<4.0.0,>=3.4.4 in /usr/local/lib/python3.11/dist-packages (from presidio-analyzer) (3.8.7)\n",
            "Collecting tldextract (from presidio-analyzer)\n",
            "  Downloading tldextract-5.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: cryptography<44.1 in /usr/lib/python3/dist-packages (from presidio-anonymizer) (3.4.8)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (0.16.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (2.11.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (3.5.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from tldextract->presidio-analyzer) (3.10)\n",
            "Collecting requests-file>=1.4 (from tldextract->presidio-analyzer)\n",
            "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.11/dist-packages (from tldextract->presidio-analyzer) (3.18.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (4.14.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (2025.4.26)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (14.0.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (2.19.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (0.1.2)\n",
            "Downloading presidio_analyzer-2.2.358-py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading presidio_anonymizer-2.2.358-py3-none-any.whl (31 kB)\n",
            "Downloading phonenumbers-8.13.55-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tldextract-5.3.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Installing collected packages: phonenumbers, presidio-anonymizer, requests-file, tldextract, presidio-analyzer\n",
            "Successfully installed phonenumbers-8.13.55 presidio-analyzer-2.2.358 presidio-anonymizer-2.2.358 requests-file-2.1.0 tldextract-5.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from presidio_analyzer import AnalyzerEngine\n",
        "from presidio_anonymizer import AnonymizerEngine\n",
        "\n",
        "#def anonymize_notes(state: dict) -> dict:\n",
        "def anonymize_notes():\n",
        "    #raw_dir = state[\"raw_notes_folder\"]\n",
        "    raw_dir = os.path.join(os.getcwd(), \"raw_clinical_notes\")\n",
        "    anon_dir = \"anonymized_clinical_notes\"\n",
        "    os.makedirs(anon_dir, exist_ok=True)\n",
        "\n",
        "    analyzer = AnalyzerEngine()\n",
        "    anonymizer = AnonymizerEngine()\n",
        "\n",
        "    for fname in os.listdir(raw_dir):\n",
        "        if not fname.endswith(\".txt\"):\n",
        "            continue\n",
        "        with open(os.path.join(raw_dir, fname), \"r\") as f:\n",
        "            text = f.read()\n",
        "\n",
        "        # Run PHI detection\n",
        "        results = analyzer.analyze(text=text, entities=None, language=\"en\")\n",
        "\n",
        "        # Anonymize detected PHI entities\n",
        "        anonymized_text = anonymizer.anonymize(text=text, analyzer_results=results).text\n",
        "\n",
        "        # Write to new anonymized file\n",
        "        new_fname = f\"anonymized_{fname}\"\n",
        "        with open(os.path.join(anon_dir, new_fname), \"w\") as out_f:\n",
        "            out_f.write(anonymized_text)\n",
        "\n",
        "#    state[\"anonymized_folder\"] = anon_dir\n",
        "#    return state\n"
      ],
      "metadata": {
        "id": "uB8HWPxH7ekG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anonymize_notes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rI7zC9VO72aZ",
        "outputId": "577db211-7f8e-4910-ace7-74387746b7ed"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:Model en_core_web_lg is not installed. Downloading...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from collections import defaultdict\n",
        "from typing import List\n",
        "from presidio_analyzer import AnalyzerEngine, RecognizerResult\n",
        "\n",
        "def extract_phi(file_path: str, analyzer: AnalyzerEngine) -> List[RecognizerResult]:\n",
        "    with open(file_path, \"r\") as f:\n",
        "        text = f.read()\n",
        "    return analyzer.analyze(text=text, entities=None, language=\"en\")\n",
        "\n",
        "#def evaluate_anonymization(state: dict) -> dict:\n",
        "def evaluate_anonymization():\n",
        "#    raw_dir = state[\"raw_notes_folder\"]\n",
        "#    anon_dir = state[\"anonymized_folder\"]\n",
        "    raw_dir = os.path.join(os.getcwd(), \"raw_clinical_notes\")\n",
        "    anon_dir = os.path.join(os.getcwd(), \"anonymized_clinical_notes\")\n",
        "    analyzer = AnalyzerEngine()\n",
        "\n",
        "    phi_counts_raw = 0\n",
        "    phi_counts_anon = 0\n",
        "\n",
        "    false_negatives = defaultdict(list)  # {file: [(entity_type, matched_text)]}\n",
        "    fileCount = len(os.listdir(raw_dir))\n",
        "\n",
        "    print(f\"Evaluating the effectiveness of the anonymizer in removing PHI across {fileCount} files\")\n",
        "\n",
        "    for fname in os.listdir(raw_dir):\n",
        "        if not fname.endswith(\".txt\"):\n",
        "            continue\n",
        "\n",
        "        raw_path = os.path.join(raw_dir, fname)\n",
        "        anon_path = os.path.join(anon_dir, f\"anonymized_{fname}\")\n",
        "\n",
        "        raw_entities = extract_phi(raw_path, analyzer)\n",
        "        anon_entities = extract_phi(anon_path, analyzer)\n",
        "\n",
        "        phi_counts_raw += len(raw_entities)\n",
        "        phi_counts_anon += len(anon_entities)\n",
        "\n",
        "        for ent in anon_entities:\n",
        "            # Changed ent.text to ent.original_text to access the matched text\n",
        "            false_negatives[fname].append((ent.entity_type, ent.contains, ent.contained_in))\n",
        "\n",
        "\n",
        "    # Compute effectiveness metric\n",
        "    if phi_counts_raw == 0:\n",
        "        effectiveness = 100.0 if phi_counts_anon == 0 else 0.0\n",
        "    else:\n",
        "        effectiveness = (1 - (phi_counts_anon / phi_counts_raw)) * 100\n",
        "\n",
        "    # Print metric summary\n",
        "    print(f\"\\n🔍 Anonymization Effectiveness: {effectiveness:.2f}%\")\n",
        "    print(f\"Total PHI elements (raw): {phi_counts_raw}\")\n",
        "    print(f\"Remaining PHI elements (anonymized): {phi_counts_anon}\\n\")\n",
        "\n",
        "    # Print false negatives summary\n",
        "    if false_negatives:\n",
        "        quarantine_dir = os.path.join(os.getcwd(), \"quarantined_clinical_notes\")\n",
        "        os.makedirs(quarantine_dir, exist_ok=True)\n",
        "        print(\"🚨 False Negatives (Missed PHI Elements):\")\n",
        "        for fname, entities in false_negatives.items():\n",
        "            print(f\"  File: {fname}\")\n",
        "            for matched_text in entities:\n",
        "                anon_fname = f\"anonymized_{fname}\"\n",
        "                source_file = os.path.join(anon_dir, \"\" + anon_fname)\n",
        "                destination_file = os.path.join(quarantine_dir, anon_fname)\n",
        "                print(f\"    -  {matched_text[1]}\")\n",
        "                print(f\"Removing file: {anon_fname} from anonymized directory as it contains PHI elements\")\n",
        "                try:\n",
        "                  shutil.move(source_file, quarantine_dir)\n",
        "                  #os.rename(source_file, destination_file)\n",
        "                except FileNotFoundError:\n",
        "                  print(f\"Source file '{source_file}' not found.\")\n",
        "                except FileExistsError:\n",
        "                  print(f\"Destination file '{destination_file}' already exists.\")\n",
        "                except OSError as e:\n",
        "                  print(f\"Error moving file: {e}\")\n",
        "        print(\"All files containing PHI elements have been moved to quarantine\")\n",
        "        print(f\"There are now {len(os.listdir(anon_dir))} files in the anonymized folder\")\n",
        "\n",
        "    else:\n",
        "        print(\"✅ No false negatives detected. All PHI was successfully removed.\")\n",
        "\n",
        "#    state[\"comparison_metric\"] = effectiveness\n",
        "#    return state\n"
      ],
      "metadata": {
        "id": "ot6US1KZ8b3x"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_anonymization()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvWeJjsJ9QPC",
        "outputId": "04e8f77f-bf83-4beb-fd9a-ce1859ed5e6e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating the effectiveness of the anonymizer in removing PHI across 900 files\n",
            "\n",
            "🔍 Anonymization Effectiveness: 99.71%\n",
            "Total PHI elements (raw): 5927\n",
            "Remaining PHI elements (anonymized): 17\n",
            "\n",
            "🚨 False Negatives (Missed PHI Elements):\n",
            "  File: clinical_note_6_for_patient_15_2025-01-29.txt\n",
            "    -  <bound method RecognizerResult.contains of type: PERSON, start: 433, end: 444, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_6_for_patient_15_2025-01-29.txt from anonymized directory as it contains PHI elements\n",
            "  File: clinical_note_0_for_patient_77_2024-09-19.txt\n",
            "    -  <bound method RecognizerResult.contains of type: PERSON, start: 431, end: 442, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_0_for_patient_77_2024-09-19.txt from anonymized directory as it contains PHI elements\n",
            "  File: clinical_note_7_for_patient_52_2024-11-14.txt\n",
            "    -  <bound method RecognizerResult.contains of type: LOCATION, start: 35, end: 53, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_7_for_patient_52_2024-11-14.txt from anonymized directory as it contains PHI elements\n",
            "  File: clinical_note_3_for_patient_24_2024-03-14.txt\n",
            "    -  <bound method RecognizerResult.contains of type: PERSON, start: 432, end: 443, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_3_for_patient_24_2024-03-14.txt from anonymized directory as it contains PHI elements\n",
            "  File: clinical_note_2_for_patient_21_2024-10-23.txt\n",
            "    -  <bound method RecognizerResult.contains of type: LOCATION, start: 35, end: 53, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_2_for_patient_21_2024-10-23.txt from anonymized directory as it contains PHI elements\n",
            "  File: clinical_note_5_for_patient_3_2023-11-19.txt\n",
            "    -  <bound method RecognizerResult.contains of type: PERSON, start: 391, end: 402, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_5_for_patient_3_2023-11-19.txt from anonymized directory as it contains PHI elements\n",
            "  File: clinical_note_6_for_patient_67_2024-06-03.txt\n",
            "    -  <bound method RecognizerResult.contains of type: LOCATION, start: 31, end: 49, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_6_for_patient_67_2024-06-03.txt from anonymized directory as it contains PHI elements\n",
            "  File: clinical_note_3_for_patient_68_2023-08-03.txt\n",
            "    -  <bound method RecognizerResult.contains of type: LOCATION, start: 31, end: 49, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_3_for_patient_68_2023-08-03.txt from anonymized directory as it contains PHI elements\n",
            "    -  <bound method RecognizerResult.contains of type: PERSON, start: 417, end: 428, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_3_for_patient_68_2023-08-03.txt from anonymized directory as it contains PHI elements\n",
            "Error moving file: Destination path '/content/quarantined_clinical_notes/anonymized_clinical_note_3_for_patient_68_2023-08-03.txt' already exists\n",
            "  File: clinical_note_0_for_patient_100_2024-10-31.txt\n",
            "    -  <bound method RecognizerResult.contains of type: PERSON, start: 427, end: 438, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_0_for_patient_100_2024-10-31.txt from anonymized directory as it contains PHI elements\n",
            "  File: clinical_note_6_for_patient_11_2023-12-14.txt\n",
            "    -  <bound method RecognizerResult.contains of type: LOCATION, start: 31, end: 49, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_6_for_patient_11_2023-12-14.txt from anonymized directory as it contains PHI elements\n",
            "  File: clinical_note_7_for_patient_18_2023-12-23.txt\n",
            "    -  <bound method RecognizerResult.contains of type: PERSON, start: 401, end: 412, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_7_for_patient_18_2023-12-23.txt from anonymized directory as it contains PHI elements\n",
            "  File: clinical_note_5_for_patient_30_2024-08-22.txt\n",
            "    -  <bound method RecognizerResult.contains of type: LOCATION, start: 35, end: 53, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_5_for_patient_30_2024-08-22.txt from anonymized directory as it contains PHI elements\n",
            "  File: clinical_note_2_for_patient_75_2023-11-18.txt\n",
            "    -  <bound method RecognizerResult.contains of type: PERSON, start: 401, end: 412, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_2_for_patient_75_2023-11-18.txt from anonymized directory as it contains PHI elements\n",
            "  File: clinical_note_7_for_patient_54_2023-10-05.txt\n",
            "    -  <bound method RecognizerResult.contains of type: PERSON, start: 416, end: 427, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_7_for_patient_54_2023-10-05.txt from anonymized directory as it contains PHI elements\n",
            "  File: clinical_note_8_for_patient_65_2025-04-13.txt\n",
            "    -  <bound method RecognizerResult.contains of type: PERSON, start: 403, end: 414, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_8_for_patient_65_2025-04-13.txt from anonymized directory as it contains PHI elements\n",
            "  File: clinical_note_1_for_patient_25_2023-11-30.txt\n",
            "    -  <bound method RecognizerResult.contains of type: PERSON, start: 444, end: 455, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_1_for_patient_25_2023-11-30.txt from anonymized directory as it contains PHI elements\n",
            "All files containing PHI elements have been moved to quarantine\n",
            "There are now 884 files in the anonymized folder\n"
          ]
        }
      ]
    }
  ]
}