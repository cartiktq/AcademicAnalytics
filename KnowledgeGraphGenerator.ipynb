{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V6E1",
      "authorship_tag": "ABX9TyPNOs/CP+1NG0odyoPAFuyI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cartiktq/AcademicAnalytics/blob/main/KnowledgeGraphGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "S = \"\"\"from langgraph.graph import StateGraph, END\n",
        "from typing import TypedDict, List, Dict, Any\n",
        "from agents import (\n",
        "    generate_notes,             # Node 1\n",
        "    anonymize_notes,           # Node 2\n",
        "    evaluate_anonymization,    # Node 3\n",
        "    extract_entities,          # Node 4\n",
        "    map_to_umls_concepts,      # Node 5\n",
        "    map_to_local_aui,          # Node 6\n",
        "    build_patient_knowledge_graph,  # Node 7\n",
        "    visualize_knowledge_graph       # Node 8\n",
        ")\n",
        "\n",
        "class WorkflowState(TypedDict):\n",
        "    raw_notes_folder: str\n",
        "    anonymized_folder: str\n",
        "    comparison_metric: float\n",
        "    extracted_csv: str\n",
        "    umls_csv: str\n",
        "    aui_csv: str\n",
        "    graph_objects: List[Dict[str, Any]]\n",
        "    visualizations: List[Any]\n",
        "\n",
        "graph = StateGraph(WorkflowState)\n",
        "\n",
        "# Register nodes\n",
        "graph.add_node(\"generate_notes\", generate_notes)\n",
        "graph.add_node(\"anonymize_notes\", anonymize_notes)\n",
        "graph.add_node(\"evaluate_anonymization\", evaluate_anonymization)\n",
        "graph.add_node(\"extract_entities\", extract_entities)\n",
        "graph.add_node(\"map_to_umls_concepts\", map_to_umls_concepts)\n",
        "graph.add_node(\"map_to_local_aui\", map_to_local_aui)\n",
        "graph.add_node(\"build_knowledge_graph\", build_patient_knowledge_graph)\n",
        "graph.add_node(\"visualize_knowledge_graph\", visualize_knowledge_graph)\n",
        "\n",
        "# Edges (linear)\n",
        "graph.set_entry_point(\"generate_notes\")\n",
        "graph.add_edge(\"generate_notes\", \"anonymize_notes\")\n",
        "graph.add_edge(\"anonymize_notes\", \"evaluate_anonymization\")\n",
        "graph.add_edge(\"evaluate_anonymization\", \"extract_entities\")\n",
        "graph.add_edge(\"extract_entities\", \"map_to_umls_concepts\")\n",
        "graph.add_edge(\"map_to_umls_concepts\", \"map_to_local_aui\")\n",
        "graph.add_edge(\"map_to_local_aui\", \"build_knowledge_graph\")\n",
        "graph.add_edge(\"build_knowledge_graph\", \"visualize_knowledge_graph\")\n",
        "graph.add_edge(\"visualize_knowledge_graph\", END)\n",
        "\n",
        "app = graph.compile()\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "I0a_eLjm1iHx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install faker transformers torch sacremoses langgraph\n",
        "! pip install presidio-analyzer presidio-anonymizer\n",
        "! pip install spacy\n",
        "! pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.3/en_ner_bc5cdr_md-0.5.3.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWHeDgCQ625k",
        "outputId": "dd4d6507-c2b8-49d6-8d61-8c6155ee5baa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faker in /usr/local/lib/python3.11/dist-packages (37.4.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cpu)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.11/dist-packages (0.1.1)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.4.8)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sacremoses) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from sacremoses) (1.5.1)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.65)\n",
            "Requirement already satisfied: langgraph-checkpoint>=2.0.26 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.26)\n",
            "Requirement already satisfied: langgraph-prebuilt>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.2.2)\n",
            "Requirement already satisfied: langgraph-sdk>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.70)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.5)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (0.3.45)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint>=2.0.26->langgraph) (1.10.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.3.1)\n",
            "Requirement already satisfied: presidio-analyzer in /usr/local/lib/python3.11/dist-packages (2.2.358)\n",
            "Requirement already satisfied: presidio-anonymizer in /usr/local/lib/python3.11/dist-packages (2.2.358)\n",
            "Requirement already satisfied: phonenumbers<9.0.0,>=8.12 in /usr/local/lib/python3.11/dist-packages (from presidio-analyzer) (8.13.55)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from presidio-analyzer) (6.0.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from presidio-analyzer) (2024.11.6)\n",
            "Requirement already satisfied: spacy!=3.7.0,<4.0.0,>=3.4.4 in /usr/local/lib/python3.11/dist-packages (from presidio-analyzer) (3.6.1)\n",
            "Requirement already satisfied: tldextract in /usr/local/lib/python3.11/dist-packages (from presidio-analyzer) (5.3.0)\n",
            "Requirement already satisfied: cryptography<44.1 in /usr/lib/python3/dist-packages (from presidio-anonymizer) (3.4.8)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (0.9.4)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (0.11.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (2.11.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (3.5.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from tldextract->presidio-analyzer) (3.10)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.11/dist-packages (from tldextract->presidio-analyzer) (2.1.0)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.11/dist-packages (from tldextract->presidio-analyzer) (3.18.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (1.3.0)\n",
            "Requirement already satisfied: pathlib-abc==0.1.1 in /usr/local/lib/python3.11/dist-packages (from pathy>=0.10.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (0.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (4.14.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (2025.4.26)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.2.0,>=8.1.8->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.2.0,>=8.1.8->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (0.1.5)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.11/dist-packages (from typer<0.10.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (8.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (1.2.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.9.4)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.11.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: pathlib-abc==0.1.1 in /usr/local/lib/python3.11/dist-packages (from pathy>=0.10.0->spacy) (0.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.5)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.11/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.3/en_ner_bc5cdr_md-0.5.3.tar.gz\n",
            "  Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.3/en_ner_bc5cdr_md-0.5.3.tar.gz (119.8 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: spacy<3.7.0,>=3.6.1 in /usr/local/lib/python3.11/dist-packages (from en_ner_bc5cdr_md==0.5.3) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (0.9.4)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (0.11.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (2.11.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (1.3.0)\n",
            "Requirement already satisfied: pathlib-abc==0.1.1 in /usr/local/lib/python3.11/dist-packages (from pathy>=0.10.0->spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (0.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (4.14.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (2025.4.26)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (0.1.5)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.11/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (8.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.7.0,>=3.6.1->en_ner_bc5cdr_md==0.5.3) (1.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#def generate_notes(state: WorkflowState) -> WorkflowState:\n",
        "def generate_notes():\n",
        "    from faker import Faker\n",
        "    import os\n",
        "    import random\n",
        "    from datetime import datetime, timedelta\n",
        "\n",
        "    fake = Faker()\n",
        "    output_dir = \"raw_clinical_notes\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    physical_symptoms = [\n",
        "    \"Developmental Delay\", \"Speech and Language Impairment\", \"Hypotonia\", \"Seizures\",\n",
        "    \"Gastrointestinal Issues\", \"Sleep Disturbances\", \"Dysmorphia\", \"Lymphedema\",\n",
        "    \"Renal Abnormalities\", \"Thermoregulation Issues\", \"Abnormalities of Nails\"\n",
        "]\n",
        "    behavioral_symptoms = [\n",
        "    \"Autism Spectrum Disorder (ASD) Features\", \"Intellectual Disability\", \"Anxiety\",\n",
        "    \"Aggression/Self-Injurious Behaviors\", \"Hyperactivity/Impulsivity\",\n",
        "    \"Sensory Processing Differences\", \"Compulsive Behaviors\", \"Mood Dysregulation\"\n",
        "]\n",
        "    prescriptions = [\n",
        "    \"Levetiracetam\", \"Valproic Acid\", \"Lamotrigine\", \"Fluoxetine\", \"Sertraline\",\n",
        "    \"Risperidone\", \"Aripiprazole\", \"Melatonin\", \"Polyethylene glycol\", \"Omeprazole\",\n",
        "    \"Ranitidine\", \"Methylphenidate\"\n",
        "]\n",
        "    lab_tests = [\n",
        "    \"Chromosomal Microarray Analysis (CMA)\", \"FISH\", \"Karyotype\", \"EEG\",\n",
        "    \"Metabolic Screens\", \"Renal Ultrasound\", \"GI Motility Studies\"\n",
        "]\n",
        "    therapies = [\n",
        "    \"Early Intervention Programs\", \"Speech and Language Therapy (SLT)\",\n",
        "    \"Occupational Therapy (OT)\", \"Physical Therapy (PT)\", \"Applied Behavior Analysis (ABA) Therapy\",\n",
        "    \"Feeding Therapy\", \"Behavioral Therapy/Parent Training\", \"Surgical Interventions\"\n",
        "]\n",
        "    comorbidities = [\n",
        "    \"Autism Spectrum Disorder (ASD)\", \"Epilepsy/Seizure Disorder\", \"Gastrointestinal Disorders\",\n",
        "    \"Sleep Disorders\", \"Anxiety Disorders\", \"ADHD\", \"Obesity\", \"Lymphedema\",\n",
        "    \"Renal Anomalies\", \"Immunodeficiency\"\n",
        "]\n",
        "\n",
        "    for patient_id in range(1, 101):\n",
        "        num_visits = random.randint(8, 10)\n",
        "        base_date = datetime.today()\n",
        "        for visit in range(num_visits):\n",
        "            visit_date = base_date - timedelta(days=random.randint(0, 365*2))\n",
        "            note = f\"\"\"\n",
        "            Patient: {fake.name()}\n",
        "            DOB: {fake.date_of_birth()}\n",
        "            Visit Date: {visit_date.strftime('%Y-%m-%d')}\n",
        "            Diagnoses: Phelan-McDermid Syndrome\n",
        "            Symptoms: {random.sample(physical_symptoms, 4)}\n",
        "            Behavioral Symptoms: {random.sample(behavioral_symptoms, 2)}\n",
        "            Labs: {random.sample(lab_tests, 2)}\n",
        "            Prescriptions: {random.sample(prescriptions, 2)}\n",
        "            Therapies: {random.sample(therapies, 2)}\n",
        "            Comorbidities: {random.sample(comorbidities, 2)}\n",
        "            \"\"\"\n",
        "            fname = f\"clinical_note_{visit}_for_patient_{patient_id}_{visit_date.strftime('%Y-%m-%d')}.txt\"\n",
        "            with open(os.path.join(output_dir, fname), \"w\") as f:\n",
        "                f.write(note)\n",
        "\n",
        "#    state[\"raw_notes_folder\"] = output_dir\n",
        "#    return state\n"
      ],
      "metadata": {
        "id": "7Oy0aVrd4tDc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_notes()"
      ],
      "metadata": {
        "id": "KrVScvMI6wFT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from presidio_analyzer import AnalyzerEngine\n",
        "from presidio_anonymizer import AnonymizerEngine\n",
        "\n",
        "#def anonymize_notes(state: dict) -> dict:\n",
        "def anonymize_notes():\n",
        "    #raw_dir = state[\"raw_notes_folder\"]\n",
        "    raw_dir = os.path.join(os.getcwd(), \"raw_clinical_notes\")\n",
        "    anon_dir = \"anonymized_clinical_notes\"\n",
        "    os.makedirs(anon_dir, exist_ok=True)\n",
        "\n",
        "    analyzer = AnalyzerEngine()\n",
        "    anonymizer = AnonymizerEngine()\n",
        "\n",
        "    for fname in os.listdir(raw_dir):\n",
        "        if not fname.endswith(\".txt\"):\n",
        "            continue\n",
        "        with open(os.path.join(raw_dir, fname), \"r\") as f:\n",
        "            text = f.read()\n",
        "\n",
        "        # Run PHI detection\n",
        "        results = analyzer.analyze(text=text, entities=None, language=\"en\")\n",
        "\n",
        "        # Anonymize detected PHI entities\n",
        "        anonymized_text = anonymizer.anonymize(text=text, analyzer_results=results).text\n",
        "\n",
        "        # Write to new anonymized file\n",
        "        new_fname = f\"anonymized_{fname}\"\n",
        "        with open(os.path.join(anon_dir, new_fname), \"w\") as out_f:\n",
        "            out_f.write(anonymized_text)\n",
        "\n",
        "#    state[\"anonymized_folder\"] = anon_dir\n",
        "#    return state\n"
      ],
      "metadata": {
        "id": "uB8HWPxH7ekG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anonymize_notes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rI7zC9VO72aZ",
        "outputId": "f99694b4-3c4e-4301-a645-a0f5c744f8c4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:Model en_core_web_lg is not installed. Downloading...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from collections import defaultdict\n",
        "from typing import List\n",
        "from presidio_analyzer import AnalyzerEngine, RecognizerResult\n",
        "\n",
        "def extract_phi(file_path: str, analyzer: AnalyzerEngine) -> List[RecognizerResult]:\n",
        "    with open(file_path, \"r\") as f:\n",
        "        text = f.read()\n",
        "    return analyzer.analyze(text=text, entities=None, language=\"en\")\n",
        "\n",
        "def quarantileFile(source_file, quarantine_dir):\n",
        "  try:\n",
        "    shutil.move(source_file, quarantine_dir)\n",
        "    #os.rename(source_file, destination_file)\n",
        "  except FileNotFoundError:\n",
        "    print(f\"Source file '{source_file}' not found.\")\n",
        "  except FileExistsError:\n",
        "    print(f\"Destination file '{destination_file}' already exists.\")\n",
        "  except OSError as e:\n",
        "    print(f\"Error moving file: {e}\")\n",
        "\n",
        "\n",
        "#def evaluate_anonymization(state: dict) -> dict:\n",
        "def evaluate_anonymization():\n",
        "#    raw_dir = state[\"raw_notes_folder\"]\n",
        "#    anon_dir = state[\"anonymized_folder\"]\n",
        "    raw_dir = os.path.join(os.getcwd(), \"raw_clinical_notes\")\n",
        "    anon_dir = os.path.join(os.getcwd(), \"anonymized_clinical_notes\")\n",
        "    analyzer = AnalyzerEngine()\n",
        "\n",
        "    phi_counts_raw = 0\n",
        "    phi_counts_anon = 0\n",
        "\n",
        "    false_negatives = defaultdict(list)  # {file: [(entity_type, matched_text)]}\n",
        "    fileCount = len(os.listdir(raw_dir))\n",
        "\n",
        "    print(f\"Evaluating the effectiveness of the anonymizer in removing PHI across {fileCount} files\")\n",
        "\n",
        "    for fname in os.listdir(raw_dir):\n",
        "        if not fname.endswith(\".txt\"):\n",
        "            continue\n",
        "\n",
        "        raw_path = os.path.join(raw_dir, fname)\n",
        "        anon_path = os.path.join(anon_dir, f\"anonymized_{fname}\")\n",
        "\n",
        "        raw_entities = extract_phi(raw_path, analyzer)\n",
        "        anon_entities = extract_phi(anon_path, analyzer)\n",
        "\n",
        "        phi_counts_raw += len(raw_entities)\n",
        "        phi_counts_anon += len(anon_entities)\n",
        "\n",
        "        for ent in anon_entities:\n",
        "            # Changed ent.text to ent.original_text to access the matched text\n",
        "            false_negatives[fname].append((ent.entity_type, ent.contains, ent.contained_in))\n",
        "\n",
        "\n",
        "    # Compute effectiveness metric\n",
        "    if phi_counts_raw == 0:\n",
        "        effectiveness = 100.0 if phi_counts_anon == 0 else 0.0\n",
        "    else:\n",
        "        effectiveness = (1 - (phi_counts_anon / phi_counts_raw)) * 100\n",
        "\n",
        "    # Print metric summary\n",
        "    print(f\"\\nüîç Anonymization Effectiveness: {effectiveness:.2f}%\")\n",
        "    print(f\"Total PHI elements (raw): {phi_counts_raw}\")\n",
        "    print(f\"Remaining PHI elements (anonymized): {phi_counts_anon}\\n\")\n",
        "\n",
        "    # Print false negatives summary\n",
        "    if false_negatives:\n",
        "        quarantine_dir = os.path.join(os.getcwd(), \"quarantined_clinical_notes\")\n",
        "        os.makedirs(quarantine_dir, exist_ok=True)\n",
        "        print(\"üö® False Negatives (Missed PHI Elements):\")\n",
        "        for fname, entities in false_negatives.items():\n",
        "            print(f\"  File: {fname}\")\n",
        "            for matched_text in entities:\n",
        "                anon_fname = f\"anonymized_{fname}\"\n",
        "                source_file = os.path.join(anon_dir, \"\" + anon_fname)\n",
        "                destination_file = os.path.join(quarantine_dir, anon_fname)\n",
        "                print(f\"    -  {matched_text[1]}\")\n",
        "                print(f\"Removing file: {anon_fname} from anonymized directory as it contains PHI elements\")\n",
        "                quarantileFile(source_file, quarantine_dir)\n",
        "        print(\"All files containing PHI elements have been moved to quarantine\")\n",
        "        print(f\"There are now {len(os.listdir(anon_dir))} files in the anonymized folder\")\n",
        "\n",
        "    else:\n",
        "        print(\"‚úÖ No false negatives detected. All PHI was successfully removed.\")\n",
        "\n",
        "#    state[\"comparison_metric\"] = effectiveness\n",
        "#    return state\n"
      ],
      "metadata": {
        "id": "ot6US1KZ8b3x"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_anonymization()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvWeJjsJ9QPC",
        "outputId": "4d291ac6-1fcf-4884-fc47-67ea004b45ed"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating the effectiveness of the anonymizer in removing PHI across 907 files\n",
            "\n",
            "üîç Anonymization Effectiveness: 99.78%\n",
            "Total PHI elements (raw): 5953\n",
            "Remaining PHI elements (anonymized): 13\n",
            "\n",
            "üö® False Negatives (Missed PHI Elements):\n",
            "  File: clinical_note_4_for_patient_92_2024-12-31.txt\n",
            "    -  <bound method RecognizerResult.contains of type: NRP, start: 22, end: 31, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_4_for_patient_92_2024-12-31.txt from anonymized directory as it contains PHI elements\n",
            "  File: clinical_note_4_for_patient_73_2025-03-04.txt\n",
            "    -  <bound method RecognizerResult.contains of type: LOCATION, start: 31, end: 49, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_4_for_patient_73_2025-03-04.txt from anonymized directory as it contains PHI elements\n",
            "  File: clinical_note_4_for_patient_70_2024-11-26.txt\n",
            "    -  <bound method RecognizerResult.contains of type: PERSON, start: 380, end: 391, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_4_for_patient_70_2024-11-26.txt from anonymized directory as it contains PHI elements\n",
            "  File: clinical_note_5_for_patient_40_2024-08-23.txt\n",
            "    -  <bound method RecognizerResult.contains of type: PERSON, start: 404, end: 415, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_5_for_patient_40_2024-08-23.txt from anonymized directory as it contains PHI elements\n",
            "  File: clinical_note_8_for_patient_78_2024-11-01.txt\n",
            "    -  <bound method RecognizerResult.contains of type: PERSON, start: 432, end: 443, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_8_for_patient_78_2024-11-01.txt from anonymized directory as it contains PHI elements\n",
            "  File: clinical_note_4_for_patient_55_2024-07-14.txt\n",
            "    -  <bound method RecognizerResult.contains of type: PERSON, start: 455, end: 466, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_4_for_patient_55_2024-07-14.txt from anonymized directory as it contains PHI elements\n",
            "  File: clinical_note_7_for_patient_5_2023-07-31.txt\n",
            "    -  <bound method RecognizerResult.contains of type: LOCATION, start: 31, end: 49, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_7_for_patient_5_2023-07-31.txt from anonymized directory as it contains PHI elements\n",
            "  File: clinical_note_6_for_patient_19_2024-07-29.txt\n",
            "    -  <bound method RecognizerResult.contains of type: LOCATION, start: 35, end: 53, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_6_for_patient_19_2024-07-29.txt from anonymized directory as it contains PHI elements\n",
            "  File: clinical_note_1_for_patient_100_2024-09-08.txt\n",
            "    -  <bound method RecognizerResult.contains of type: PERSON, start: 435, end: 446, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_1_for_patient_100_2024-09-08.txt from anonymized directory as it contains PHI elements\n",
            "  File: clinical_note_9_for_patient_17_2024-04-03.txt\n",
            "    -  <bound method RecognizerResult.contains of type: LOCATION, start: 31, end: 49, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_9_for_patient_17_2024-04-03.txt from anonymized directory as it contains PHI elements\n",
            "  File: clinical_note_2_for_patient_72_2024-05-14.txt\n",
            "    -  <bound method RecognizerResult.contains of type: LOCATION, start: 31, end: 49, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_2_for_patient_72_2024-05-14.txt from anonymized directory as it contains PHI elements\n",
            "  File: clinical_note_4_for_patient_72_2024-10-16.txt\n",
            "    -  <bound method RecognizerResult.contains of type: LOCATION, start: 35, end: 53, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_4_for_patient_72_2024-10-16.txt from anonymized directory as it contains PHI elements\n",
            "  File: clinical_note_5_for_patient_38_2023-12-26.txt\n",
            "    -  <bound method RecognizerResult.contains of type: PERSON, start: 432, end: 443, score: 0.85>\n",
            "Removing file: anonymized_clinical_note_5_for_patient_38_2023-12-26.txt from anonymized directory as it contains PHI elements\n",
            "All files containing PHI elements have been moved to quarantine\n",
            "There are now 894 files in the anonymized folder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import uuid\n",
        "import spacy\n",
        "\n",
        "#def extract_entities(state: dict) -> dict:\n",
        "def extract_entities():\n",
        "#    anonymized_dir = state[\"anonymized_folder\"]\n",
        "    anonymized_dir = \"anonymized_clinical_notes\"\n",
        "    output_csv = \"extracted_entity_triples.csv\"\n",
        "\n",
        "    # Load scispaCy model\n",
        "    nlp = spacy.load(\"en_ner_bc5cdr_md\")\n",
        "\n",
        "    # Define mapping from keyword match to relation\n",
        "    verb_mapping = {\n",
        "        \"lab\": [\"EEG\", \"CMA\", \"Karyotype\", \"FISH\", \"Metabolic\", \"Ultrasound\", \"GI\"],\n",
        "        \"diagnosis\": [\"syndrome\", \"diagnosis\", \"disorder\"],\n",
        "        \"comorbidity\": [\"ASD\", \"anxiety\", \"obesity\", \"sleep\", \"ADHD\", \"epilepsy\", \"renal\"],\n",
        "        \"procedure\": [\"surgery\", \"microarray\", \"biopsy\"],\n",
        "        \"therapy\": [\"therapy\", \"intervention\", \"training\"],\n",
        "        \"symptom\": [\"delay\", \"impairment\", \"hypotonia\", \"seizure\", \"disturbance\", \"abnormality\"],\n",
        "        \"behavior\": [\"aggression\", \"mood\", \"anxiety\", \"compulsive\", \"impulsivity\", \"sensory\"],\n",
        "        \"prescription\": [\"ine\", \"acid\", \"ole\", \"zol\", \"phenidate\", \"melatonin\"]\n",
        "    }\n",
        "\n",
        "    def classify_relation(entity_text: str):\n",
        "        text_lower = entity_text.lower()\n",
        "        for relation, keywords in verb_mapping.items():\n",
        "            for kw in keywords:\n",
        "                if kw.lower() in text_lower:\n",
        "                    return relation\n",
        "        return \"misc\"\n",
        "\n",
        "    rows = []\n",
        "\n",
        "    for fname in os.listdir(anonymized_dir):\n",
        "        if not fname.endswith(\".txt\"):\n",
        "            continue\n",
        "\n",
        "        patient_id = str(uuid.uuid4())  # Generate unique patient ID\n",
        "        file_path = os.path.join(os.getcwd(), anonymized_dir, fname)\n",
        "        with open(file_path, \"r\") as f:\n",
        "            text = f.read()\n",
        "\n",
        "        # Extract visit date from file name\n",
        "        try:\n",
        "            visit_date = fname.split(\"_\")[-1].replace(\".txt\", \"\")\n",
        "        except:\n",
        "            visit_date = \"unknown\"\n",
        "\n",
        "        # Run NER\n",
        "        doc = nlp(text)\n",
        "        for ent in doc.ents:\n",
        "            verb = classify_relation(ent.text)\n",
        "            if verb == \"lab\":\n",
        "                rows.append([patient_id, verb, ent.text, visit_date])\n",
        "                rows.append([patient_id, \"result\", f\"{ent.text} result pending\", visit_date])\n",
        "            else:\n",
        "                rows.append([patient_id, verb, ent.text, visit_date])\n",
        "\n",
        "    # Write triples to CSV\n",
        "    with open(output_csv, \"w\", newline=\"\") as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow([\"patient_id\", \"relation\", \"entity\", \"date\"])\n",
        "        writer.writerows(rows)\n",
        "\n",
        "#    state[\"extracted_csv\"] = output_csv\n",
        "#    return state\n"
      ],
      "metadata": {
        "id": "JRY9VCdkpW2S"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_entities()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UY7zhd9lqhiY",
        "outputId": "41c588d7-2133-426e-d233-dba85d69f08d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/language.py:2141: FutureWarning: Possible set union at position 6328\n",
            "  deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(  # type: ignore[union-attr]\n"
          ]
        }
      ]
    }
  ]
}